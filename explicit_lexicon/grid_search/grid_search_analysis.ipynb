{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "As most runs achieve maximal reward ($R=1$) at the end, comparing that value is not useful. Therefore, we use the cumulative rewards instead. \n",
    "\n",
    "The hyperparameter search was conducted for interval size $k=10$. As a new word is added every $10$ epochs, after $1000$ epochs the data set contains all words. Note, that data size in the hyperparameter search refers to the number of examples the agent gets to see per epoch, and not the number of words it must learn. We trained for $1500$ epochs in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_rewards_fixed = []\n",
    "min_rewards_fixed = []\n",
    "param_list = []\n",
    "rewards_fixed = []\n",
    "for data_size in [100,1000]:\n",
    "    for alpha in [5.]:\n",
    "        for batch_size in [16, 32]:\n",
    "            for learning_rate in [0.001,0.01,0.1]:\n",
    "                for lexicon_init in [0.0001, 0.001,0.01,0.1]:\n",
    "                    filename = ('fixed_lexicon/' + str(data_size) + 'datasize_' + str(batch_size) + 'batchsize_' + \n",
    "                                    str(alpha) + 'alpha_' + str(learning_rate) + 'lr_' + str(lexicon_init) + 'init/')\n",
    "                    reward = np.load(filename + 'rewards_0.npy')\n",
    "                    rewards_fixed.append(reward)\n",
    "                    sum_rewards_fixed.append(np.sum(reward))\n",
    "                    min_rewards_fixed.append(np.min(reward))\n",
    "                    param_list.append([data_size, alpha, batch_size, learning_rate, lexicon_init])\n",
    "                    # print(counter, param_list[-1])\n",
    "                    # counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ranking_fixed = np.argsort(-np.array(sum_rewards_fixed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 5.0, 32, 0.01, 0.001] 1495.2711\n",
      "[1000, 5.0, 32, 0.1, 0.001] 1495.2278\n",
      "[1000, 5.0, 32, 0.001, 0.0001] 1495.2207\n",
      "[1000, 5.0, 16, 0.01, 0.0001] 1495.1543\n",
      "[1000, 5.0, 16, 0.001, 0.0001] 1495.125\n",
      "[1000, 5.0, 16, 0.01, 0.001] 1495.0343\n",
      "[1000, 5.0, 32, 0.001, 0.001] 1494.9476\n",
      "[1000, 5.0, 16, 0.1, 0.0001] 1494.7793\n",
      "[1000, 5.0, 16, 0.1, 0.01] 1494.6965\n",
      "[1000, 5.0, 32, 0.1, 0.01] 1494.5676\n",
      "[1000, 5.0, 32, 0.1, 0.0001] 1494.5515\n",
      "[1000, 5.0, 16, 0.01, 0.01] 1494.1775\n",
      "[1000, 5.0, 32, 0.01, 0.01] 1494.123\n",
      "[1000, 5.0, 16, 0.1, 0.001] 1494.1018\n",
      "[1000, 5.0, 32, 0.01, 0.0001] 1493.9718\n",
      "[1000, 5.0, 16, 0.001, 0.001] 1493.7268\n",
      "[1000, 5.0, 16, 0.001, 0.01] 1490.9417\n",
      "[1000, 5.0, 16, 0.1, 0.1] 1490.2542\n",
      "[1000, 5.0, 32, 0.001, 0.01] 1487.7622\n",
      "[1000, 5.0, 32, 0.1, 0.1] 1485.498\n",
      "[1000, 5.0, 16, 0.01, 0.1] 1457.7783\n",
      "[100, 5.0, 32, 0.1, 0.01] 1456.3645\n",
      "[100, 5.0, 16, 0.1, 0.0001] 1452.448\n",
      "[100, 5.0, 16, 0.01, 0.0001] 1451.875\n",
      "[100, 5.0, 16, 0.001, 0.0001] 1451.6042\n",
      "[100, 5.0, 16, 0.01, 0.01] 1450.5625\n",
      "[100, 5.0, 16, 0.1, 0.001] 1450.1666\n",
      "[100, 5.0, 16, 0.1, 0.01] 1449.9375\n",
      "[100, 5.0, 32, 0.001, 0.001] 1449.5938\n",
      "[100, 5.0, 32, 0.01, 0.001] 1445.9896\n",
      "[100, 5.0, 32, 0.01, 0.01] 1445.1458\n",
      "[100, 5.0, 32, 0.01, 0.0001] 1444.1354\n",
      "[100, 5.0, 32, 0.1, 0.0001] 1441.5\n",
      "[100, 5.0, 16, 0.001, 0.001] 1440.7395\n",
      "[100, 5.0, 16, 0.01, 0.001] 1440.1354\n",
      "[100, 5.0, 32, 0.001, 0.0001] 1440.0729\n",
      "[100, 5.0, 32, 0.1, 0.001] 1439.5\n",
      "[1000, 5.0, 32, 0.01, 0.1] 1428.0212\n",
      "[100, 5.0, 16, 0.001, 0.01] 1419.9166\n",
      "[100, 5.0, 16, 0.1, 0.1] 1406.3958\n",
      "[100, 5.0, 32, 0.001, 0.01] 1392.125\n",
      "[100, 5.0, 32, 0.1, 0.1] 1380.9792\n",
      "[1000, 5.0, 16, 0.001, 0.1] 1261.4556\n",
      "[100, 5.0, 16, 0.01, 0.1] 1241.7292\n",
      "[1000, 5.0, 32, 0.001, 0.1] 1102.7883\n",
      "[100, 5.0, 32, 0.01, 0.1] 1082.8646\n",
      "[100, 5.0, 16, 0.001, 0.1] 587.6146\n",
      "[100, 5.0, 32, 0.001, 0.1] 417.6354\n"
     ]
    }
   ],
   "source": [
    "for i in max_ranking_fixed:\n",
    "    print(param_list[i], sum_rewards_fixed[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 5.0, 32, 0.01, 0.001] 1495.2711 0.859879\n",
      "[1000, 5.0, 32, 0.1, 0.001] 1495.2278 0.8719758\n",
      "[1000, 5.0, 32, 0.001, 0.0001] 1495.2207 0.88810486\n",
      "[1000, 5.0, 16, 0.01, 0.0001] 1495.1543 0.9153226\n",
      "[1000, 5.0, 16, 0.001, 0.0001] 1495.125 0.8921371\n",
      "[1000, 5.0, 16, 0.01, 0.001] 1495.0343 0.8679435\n",
      "[1000, 5.0, 32, 0.001, 0.001] 1494.9476 0.8155242\n",
      "[1000, 5.0, 16, 0.1, 0.0001] 1494.7793 0.7429435\n",
      "[1000, 5.0, 16, 0.1, 0.01] 1494.6965 0.922379\n",
      "[1000, 5.0, 32, 0.1, 0.01] 1494.5676 0.83971775\n"
     ]
    }
   ],
   "source": [
    "for idx in max_ranking_fixed[0:10]:\n",
    "    print(param_list[idx], sum_rewards_fixed[idx], min_rewards_fixed[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_rewards_dynamic = []\n",
    "min_rewards_dynamic = []\n",
    "param_list = []\n",
    "rewards_dynamic = []\n",
    "for data_size in [100,1000]:\n",
    "    for alpha in [5.]:\n",
    "        for batch_size in [16, 32]:\n",
    "            for learning_rate in [0.001,0.01,0.1]:\n",
    "                for lexicon_init in [0.0001,0.001,0.01,0.1]:\n",
    "                    filename = ('dynamic_lexicon/' + str(data_size) + 'datasize_' + str(batch_size) + 'batchsize_' + \n",
    "                                        str(alpha) + 'alpha_' + str(learning_rate) + 'lr_' + str(lexicon_init) + 'init/')\n",
    "                    reward = np.load(filename + 'rewards_0.npy')\n",
    "                    rewards_dynamic.append(reward)\n",
    "                    sum_rewards_dynamic.append(np.sum(reward))\n",
    "                    min_rewards_dynamic.append(np.min(reward))\n",
    "                    param_list.append([data_size, alpha, batch_size, learning_rate, lexicon_init])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 5.0, 16, 0.01, 0.1] 1499.0807\n",
      "[1000, 5.0, 32, 0.1, 0.1] 1499.0272\n",
      "[1000, 5.0, 16, 0.1, 0.1] 1498.7168\n",
      "[1000, 5.0, 32, 0.01, 0.1] 1498.5203\n",
      "[1000, 5.0, 16, 0.001, 0.01] 1498.0989\n",
      "[1000, 5.0, 32, 0.001, 0.01] 1497.5999\n",
      "[1000, 5.0, 16, 0.001, 0.1] 1495.6794\n",
      "[1000, 5.0, 16, 0.01, 0.01] 1492.7087\n",
      "[1000, 5.0, 32, 0.01, 0.01] 1492.121\n",
      "[1000, 5.0, 32, 0.001, 0.1] 1487.5414\n",
      "[100, 5.0, 32, 0.001, 0.01] 1484.7812\n",
      "[100, 5.0, 16, 0.001, 0.01] 1480.7083\n",
      "[100, 5.0, 32, 0.01, 0.1] 1474.052\n",
      "[100, 5.0, 16, 0.01, 0.1] 1473.0625\n",
      "[100, 5.0, 16, 0.1, 0.1] 1472.7916\n",
      "[100, 5.0, 32, 0.1, 0.1] 1459.7916\n",
      "[1000, 5.0, 16, 0.001, 0.001] 1393.864\n",
      "[100, 5.0, 16, 0.001, 0.1] 1316.6875\n",
      "[100, 5.0, 16, 0.01, 0.01] 1185.875\n",
      "[1000, 5.0, 32, 0.001, 0.001] 1092.5876\n",
      "[1000, 5.0, 16, 0.1, 0.01] 1022.1522\n",
      "[100, 5.0, 32, 0.001, 0.1] 1010.8854\n",
      "[1000, 5.0, 32, 0.1, 0.01] 965.03937\n",
      "[100, 5.0, 32, 0.01, 0.01] 841.1458\n",
      "[100, 5.0, 16, 0.1, 0.01] 668.82294\n",
      "[1000, 5.0, 16, 0.01, 0.001] 583.63007\n",
      "[100, 5.0, 16, 0.001, 0.001] 457.98956\n",
      "[100, 5.0, 32, 0.1, 0.01] 442.3021\n",
      "[1000, 5.0, 32, 0.01, 0.001] 374.1502\n",
      "[100, 5.0, 32, 0.001, 0.001] 369.11456\n",
      "[1000, 5.0, 16, 0.001, 0.0001] 251.3004\n",
      "[1000, 5.0, 16, 0.1, 0.001] 250.07965\n",
      "[100, 5.0, 16, 0.01, 0.001] 233.07292\n",
      "[100, 5.0, 32, 0.01, 0.001] 230.89583\n",
      "[1000, 5.0, 32, 0.001, 0.0001] 210.99295\n",
      "[1000, 5.0, 32, 0.1, 0.001] 210.376\n",
      "[100, 5.0, 16, 0.001, 0.0001] 207.5625\n",
      "[1000, 5.0, 32, 0.01, 0.0001] 206.38307\n",
      "[1000, 5.0, 16, 0.01, 0.0001] 205.18547\n",
      "[100, 5.0, 16, 0.1, 0.001] 201.625\n",
      "[100, 5.0, 32, 0.1, 0.001] 200.66666\n",
      "[100, 5.0, 32, 0.01, 0.0001] 200.57294\n",
      "[100, 5.0, 16, 0.1, 0.0001] 200.42706\n",
      "[100, 5.0, 32, 0.001, 0.0001] 200.34375\n",
      "[100, 5.0, 32, 0.1, 0.0001] 200.15627\n",
      "[1000, 5.0, 32, 0.1, 0.0001] 199.87903\n",
      "[1000, 5.0, 16, 0.1, 0.0001] 199.34476\n",
      "[100, 5.0, 16, 0.01, 0.0001] 199.16667\n"
     ]
    }
   ],
   "source": [
    "max_ranking_dynamic = np.argsort(-np.array(sum_rewards_dynamic))\n",
    "for i in max_ranking_dynamic:\n",
    "    print(param_list[i], sum_rewards_dynamic[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 5.0, 16, 0.01, 0.1] 1499.0807\n",
      "[1000, 5.0, 32, 0.1, 0.1] 1499.0272\n",
      "[1000, 5.0, 16, 0.1, 0.1] 1498.7168\n",
      "[1000, 5.0, 32, 0.01, 0.1] 1498.5203\n",
      "[1000, 5.0, 16, 0.001, 0.01] 1498.0989\n",
      "[1000, 5.0, 32, 0.001, 0.01] 1497.5999\n",
      "[1000, 5.0, 16, 0.001, 0.1] 1495.6794\n",
      "[1000, 5.0, 16, 0.01, 0.01] 1492.7087\n",
      "[1000, 5.0, 32, 0.01, 0.01] 1492.121\n",
      "[1000, 5.0, 32, 0.001, 0.1] 1487.5414\n"
     ]
    }
   ],
   "source": [
    "for idx in max_ranking_dynamic[0:10]:\n",
    "    print(param_list[idx], sum_rewards_dynamic[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the between lexicon comparison, we ignore the lexicon initializtion. The intial lexicon sizes, and therefore the number of parameters are so different between the implementations, that different initializations make sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 5.0, 32, 0.01, 0.001] 1495.2711\n",
      "[1000, 5.0, 32, 0.1, 0.001] 1495.2278\n",
      "[1000, 5.0, 32, 0.001, 0.0001] 1495.2207\n",
      "[1000, 5.0, 16, 0.01, 0.0001] 1495.1543\n",
      "[1000, 5.0, 16, 0.001, 0.0001] 1495.125\n"
     ]
    }
   ],
   "source": [
    "for idx in max_ranking_fixed[0:5]:\n",
    "    print(param_list[idx], sum_rewards_fixed[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 5.0, 16, 0.01, 0.1] 1499.0807\n",
      "[1000, 5.0, 32, 0.1, 0.1] 1499.0272\n",
      "[1000, 5.0, 16, 0.1, 0.1] 1498.7168\n",
      "[1000, 5.0, 32, 0.01, 0.1] 1498.5203\n",
      "[1000, 5.0, 16, 0.001, 0.01] 1498.0989\n"
     ]
    }
   ],
   "source": [
    "for idx in max_ranking_dynamic[0:5]:\n",
    "    print(param_list[idx], sum_rewards_dynamic[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rightarrow$ The best hyperparameters across implementation are\n",
    "\n",
    "* data size : 1000\n",
    "* batch size: 32 \n",
    "* learning rate: 0.1\n",
    "\n",
    "$\\rightarrow$ For the initialization we choose: 0.001 for the fixed lexicon, and 0.1 for the dynamic lexicon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
